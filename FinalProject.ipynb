{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ad2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patoolib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cd0cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "patoolib.extract_archive(\"BreastCancer_IDC_Grade_1.rar\", outdir = \"BC_Grade1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813b06ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "patoolib.extract_archive(\"BreastCancer_IDC_Grade_2.rar\", outdir = \"BC_Grade2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32df1daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "patoolib.extract_archive(\"BreastCancer_IDC_Grade_3.rar\", outdir = \"BC_Grade3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from skimage.color import rgb2hed, hed2rgb, rgb2gray\n",
    "from skimage.exposure import match_histograms\n",
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42104ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path1 = 'BC_Grade1/BC_IDC_Grade_1/Samples'\n",
    "folder_path2 = 'BC_Grade2/BC_IDC_Grade_2/Samples'\n",
    "folder_path3 = 'BC_Grade3/BC_IDC_Grade_3/Samples'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf47e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpen_image(image):\n",
    "    blurred = gaussian(image, sigma=1)\n",
    "    alpha = 3\n",
    "    sharpened = np.clip(image + alpha * (image - blurred), 0, 1)\n",
    "    return sharpened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://www.geeksforgeeks.org/histogram-matching-with-opencv-scikit-image-and-python/\n",
    "folder_path1 = 'BC_Grade1/BC_IDC_Grade_1/Samples'\n",
    "target_image_path = 'BC_Grade1/BC_IDC_Grade_1/Samples/02_BC_G1_9103_40x_1.JPG'\n",
    "enhanced_folder_path = os.path.join(folder_path1, \"enhanced\")\n",
    "eosin_intensity_scale = 1.5\n",
    "hematoxylin_intensity_scale = 1.1 \n",
    "\n",
    "if not os.path.exists(enhanced_folder_path):\n",
    "    os.mkdir(enhanced_folder_path)\n",
    "    \n",
    "image_files = [f for f in os.listdir(folder_path1) if f.endswith(('.JPG', '.jpg'))]\n",
    "\n",
    "target_img = io.imread(target_image_path)\n",
    "target_hed = rgb2hed(target_img)\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path1, image_file)\n",
    "    \n",
    "    source_img = io.imread(image_path)/255\n",
    "    source_hed = rgb2hed(source_img)\n",
    "    \n",
    "    grayscale = rgb2gray(source_img)\n",
    "    thresh = threshold_otsu(grayscale)\n",
    "    mask = grayscale < thresh\n",
    "    \n",
    "    for i in range(3):\n",
    "        source_channel = source_hed[:, :, i]\n",
    "        target_channel = target_hed[:, :, i]\n",
    "        matched_channel = match_histograms(source_channel, target_channel)   \n",
    "        \n",
    "        source_hed[mask, i] = matched_channel[mask]\n",
    "    \n",
    "    \n",
    "    source_hed[:, :, 1] = np.clip(source_hed[:, :, 1] * eosin_intensity_scale, 0, 1)\n",
    "    source_hed[:, :, 0] = np.clip(source_hed[:, :, 0] * hematoxylin_intensity_scale, 0, 1)\n",
    "\n",
    "    \n",
    "    normalized_rgb = hed2rgb(source_hed)\n",
    "    sharpened_rgb = sharpen_image(normalized_rgb)\n",
    "    \n",
    "    save_path = os.path.join(enhanced_folder_path, image_file)\n",
    "    io.imsave(save_path, (sharpened_rgb * 255).astype(np.uint8))\n",
    "    \n",
    "    #plt.figure(figsize=(10, 5))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    #plt.imshow(source_img)\n",
    "    #plt.title('Original Image')\n",
    "\n",
    "    #plt.subplot(1, 2, 2)\n",
    "    #plt.imshow(sharpened_rgb)\n",
    "    #plt.title('Normalized Image')\n",
    "    #plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344e724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path2 = 'BC_Grade2/BC_IDC_Grade_2/Samples'\n",
    "target_image_path = 'BC_Grade1/BC_IDC_Grade_1/Samples/02_BC_G1_9103_40x_1.JPG'\n",
    "enhanced_folder_path = os.path.join(folder_path2, \"enhanced\")\n",
    "eosin_intensity_scale = 1.5\n",
    "hematoxylin_intensity_scale = 1.1 \n",
    "\n",
    "if not os.path.exists(enhanced_folder_path):\n",
    "    os.mkdir(enhanced_folder_path)\n",
    "    \n",
    "image_files = [f for f in os.listdir(folder_path2) if f.endswith(('.JPG', '.jpg'))]\n",
    "\n",
    "target_img = io.imread(target_image_path)\n",
    "target_hed = rgb2hed(target_img)\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path2, image_file)\n",
    "    \n",
    "    source_img = io.imread(image_path)\n",
    "    source_hed = rgb2hed(source_img)\n",
    "    \n",
    "    grayscale = rgb2gray(source_img)\n",
    "    thresh = threshold_otsu(grayscale)\n",
    "    mask = grayscale < thresh\n",
    "    \n",
    "    for i in range(3):\n",
    "        source_channel = source_hed[:, :, i]\n",
    "        target_channel = target_hed[:, :, i]\n",
    "        matched_channel = match_histograms(source_channel, target_channel)   \n",
    "        \n",
    "        source_hed[mask, i] = matched_channel[mask]\n",
    "    \n",
    "    \n",
    "    source_hed[:, :, 1] = np.clip(source_hed[:, :, 1] * eosin_intensity_scale, 0, 1)\n",
    "    source_hed[:, :, 0] = np.clip(source_hed[:, :, 0] * hematoxylin_intensity_scale, 0, 1)\n",
    "\n",
    "    \n",
    "    normalized_rgb = hed2rgb(source_hed)\n",
    "    sharpened_rgb = sharpen_image(normalized_rgb)\n",
    "    \n",
    "    save_path = os.path.join(enhanced_folder_path, image_file)\n",
    "    io.imsave(save_path, (sharpened_rgb * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3563e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path3 = 'BC_Grade3/BC_IDC_Grade_3/Samples'\n",
    "target_image_path = 'BC_Grade1/BC_IDC_Grade_1/Samples/02_BC_G1_9103_40x_1.JPG'\n",
    "enhanced_folder_path = os.path.join(folder_path3, \"enhanced\")\n",
    "eosin_intensity_scale = 1.5\n",
    "hematoxylin_intensity_scale = 1.1 \n",
    "\n",
    "if not os.path.exists(enhanced_folder_path):\n",
    "    os.mkdir(enhanced_folder_path)\n",
    "    \n",
    "image_files = [f for f in os.listdir(folder_path3) if f.endswith(('.JPG', '.jpg'))]\n",
    "\n",
    "target_img = io.imread(target_image_path)\n",
    "target_hed = rgb2hed(target_img)\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_path = os.path.join(folder_path3, image_file)\n",
    "    \n",
    "    source_img = io.imread(image_path)\n",
    "    source_hed = rgb2hed(source_img)\n",
    "    \n",
    "    grayscale = rgb2gray(source_img)\n",
    "    thresh = threshold_otsu(grayscale)\n",
    "    mask = grayscale < thresh\n",
    "    \n",
    "    for i in range(3):\n",
    "        source_channel = source_hed[:, :, i]\n",
    "        target_channel = target_hed[:, :, i]\n",
    "        matched_channel = match_histograms(source_channel, target_channel)   \n",
    "        \n",
    "        source_hed[mask, i] = matched_channel[mask]\n",
    "    \n",
    "    \n",
    "    source_hed[:, :, 1] = np.clip(source_hed[:, :, 1] * eosin_intensity_scale, 0, 1)\n",
    "    source_hed[:, :, 0] = np.clip(source_hed[:, :, 0] * hematoxylin_intensity_scale, 0, 1)\n",
    "\n",
    "    \n",
    "    normalized_rgb = hed2rgb(source_hed)\n",
    "    sharpened_rgb = sharpen_image(normalized_rgb)\n",
    "    \n",
    "    save_path = os.path.join(enhanced_folder_path, image_file)\n",
    "    io.imsave(save_path, (sharpened_rgb * 255).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a100e1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fd8a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_path1 = 'BC_Grade1/BC_IDC_Grade_1/Samples/enhanced'\n",
    "e_path2 = 'BC_Grade2/BC_IDC_Grade_2/Samples/enhanced'\n",
    "e_path3 = 'BC_Grade3/BC_IDC_Grade_3/Samples/enhanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee21856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29c01a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder_path, target_size=(224, 224)):\n",
    "    image_files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.endswith(('.JPG', '.jpg'))]\n",
    "    images = []\n",
    "\n",
    "    for image_file in image_files:\n",
    "        img_path = os.path.join(folder_path, image_file)\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
    "        if img is not None:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img_resized = cv2.resize(img, target_size)   \n",
    "            images.append(img_resized)\n",
    "    \n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6572d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCStage1 = load_images_from_folder(e_path1)\n",
    "BCStage2 = load_images_from_folder(e_path2)\n",
    "BCStage3 = load_images_from_folder(e_path3)\n",
    "\n",
    "# code adapted from https://machinelearningknowledge.ai/numpy-zeros-numpy-ones-and-numpy-eye-in-python/?utm_content=cmp-true\n",
    "labels_stage1 = np.zeros((BCStage1.shape[0],)) \n",
    "labels_stage2 = np.ones((BCStage2.shape[0],))    \n",
    "labels_stage3 = 2 * np.ones((BCStage3.shape[0],)) \n",
    "\n",
    "X = np.concatenate([BCStage1, BCStage2 ,BCStage3 ], axis=0)\n",
    "y = np.concatenate([labels_stage1, labels_stage2, labels_stage3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a93a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test_temp, y_train, y_test_temp = train_test_split(X, y, test_size=0.2, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b39ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, X_test, y_val, y_test = train_test_split(X_test_temp, y_test_temp, test_size=0.5, random_state=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e16f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug = ImageDataGenerator(\n",
    "    rotation_range=40,            \n",
    "    width_shift_range=0.2,        \n",
    "    height_shift_range=0.2,      \n",
    "    shear_range=0.2,             \n",
    "    zoom_range=[1.0, 1.2],              \n",
    "    horizontal_flip=True, \n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ccc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataAug.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110bedb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7582253",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train)\n",
    "X_val = preprocess_input(X_val)\n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a9efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick between the model using model API or Sequential API, do not run both as it wont work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa87d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "       \n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x) \n",
    "x = Dense(3, activation='softmax')(x)  \n",
    "VGGmodel = Model(base_model.input, x)\n",
    "VGGmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e21f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "VGGmodel = Sequential()\n",
    "VGGmodel.add(base_model)\n",
    "VGGmodel.add(GlobalAveragePooling2D())\n",
    "VGGmodel.add(Dense(512, activation='relu'))\n",
    "VGGmodel.add(BatchNormalization())\n",
    "VGGmodel.add(Dropout(0.5))\n",
    "VGGmodel.add(Dense(3, activation='softmax'))\n",
    "\n",
    "VGGmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae31438",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGmodel.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042f44f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGGmodel.fit( X_train, y_train,\n",
    "           validation_data=(X_val, y_val),\n",
    "           epochs=10,\n",
    "           batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d58cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = VGGmodel.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9ceca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "predictions = VGGmodel.predict(X_test)  \n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = y_test\n",
    "\n",
    "f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6666b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code adapted from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "predictions = VGGmodel.predict(X_test)\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "conf_matrix = confusion_matrix(y_test, predicted_labels)\n",
    "\n",
    "class_names = ['0', '1', '2'] \n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values ')\n",
    "plt.title('VGG-16: Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6c566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code adapted from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html\n",
    "#code adapted from https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "y_pred_prob = VGGmodel.predict(X_test)\n",
    "\n",
    "num_classes = y_pred_prob.shape[1]\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "auc = {}\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test == i, y_pred_prob[:, i])\n",
    "    auc[i] = roc_auc_score(y_test == i, y_pred_prob[:, i])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label=f'ROC Curve of Class {i} (AUC = {auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('VGG-16: ROC Curves')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
